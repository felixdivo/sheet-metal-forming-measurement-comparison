{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72b7a788",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "data_dir = Path.cwd() / \"data\"\n",
    "assert data_dir.exists(), f\"Data directory does not exist: {data_dir}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a8bff20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from copy import copy\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "from rich.progress import track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c942c83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "first = json.loads(\n",
    "    (data_dir / \"Versuch_V4_T2_A1_Dec-18-25__19_26.json\").read_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad32fc71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dc98a03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['meta_data', 'expert_knowledge', 'data'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ec5c90a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset': 'SPP2422_experiment_tdms',\n",
       " 'origin': 'experiment',\n",
       " 'program': 'LabVIEW/NI TDMS',\n",
       " 'description': 'TDMS measurement V4_T2_A1 | file=Versuch_V4_T2_A1_Dec-18-25__19_26.tdms',\n",
       " 'created_utc': '2026-01-11T12:39:38.292358Z',\n",
       " 'source_file': 'Versuch_V4_T2_A1_Dec-18-25__19_26.tdms',\n",
       " 'group_name': 'Messergebnisse_V4_T2_A1',\n",
       " 'V': 4,\n",
       " 'T': 2,\n",
       " 'A': 1,\n",
       " 'export': {'target_length': 1200, 'max_hubs_per_file': None},\n",
       " 'channel_mapping': {'K1_Ch1_Mod2/AI0': 'K1_Ch1_Mod2__AI0',\n",
       "  'K1_Ch2_Mod2/AI1': 'K1_Ch2_Mod2__AI1',\n",
       "  'K1_Ch3_Mod2/AI2': 'K1_Ch3_Mod2__AI2',\n",
       "  'K2_Ch1_Mod2/AI3': 'K2_Ch1_Mod2__AI3',\n",
       "  'K2_Ch2_Mod2/AI4': 'K2_Ch2_Mod2__AI4',\n",
       "  'K2_Ch3_Mod2/AI5': 'K2_Ch3_Mod2__AI5',\n",
       "  'K3_Ch1_Mod2/AI6': 'K3_Ch1_Mod2__AI6',\n",
       "  'K3_Ch2_Mod2/AI7': 'K3_Ch2_Mod2__AI7',\n",
       "  'K3_Ch3_Mod2/AI8': 'K3_Ch3_Mod2__AI8',\n",
       "  'Mod2/AI9': 'Mod2__AI9',\n",
       "  'Mod7 A0': 'Mod7_A0',\n",
       "  'Mod7 A1': 'Mod7_A1',\n",
       "  'Mod7 A2': 'Mod7_A2',\n",
       "  'Mod7 A3': 'Mod7_A3'},\n",
       " 'hub_index': 1,\n",
       " 'hub_range_samples': [197, 10453],\n",
       " 'stroke': 0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first[0][\"meta_data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42aefac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'textual_insight': '', 'extracted_features': {}}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first[0][\"expert_knowledge\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cd52d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['name', 'label', 'label_unit', 'level', 'origin', 'i.O/n.i.O', 'time_s', 'signals'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first[0][\"data\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d62364c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Versuch_V4_T2_A1_Dec-18-25__19_26__hub0001',\n",
       " 'label': None,\n",
       " 'label_unit': None,\n",
       " 'level': 1,\n",
       " 'origin': 'experiment',\n",
       " 'i.O/n.i.O': None}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simpler = copy(first[0][\"data\"])\n",
    "del simpler[\"time_s\"]\n",
    "del simpler[\"signals\"]\n",
    "simpler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9363e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1200,), [0.0, 0.5, 1.0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = np.array(first[0][\"data\"][\"time_s\"])\n",
    "t.shape, [t.min().item(), t.mean().item(), t.max().item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "518f599e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['K1_Ch1_Mod2__AI0', 'K1_Ch2_Mod2__AI1', 'K1_Ch3_Mod2__AI2', 'K2_Ch1_Mod2__AI3', 'K2_Ch2_Mod2__AI4', 'K2_Ch3_Mod2__AI5', 'K3_Ch1_Mod2__AI6', 'K3_Ch2_Mod2__AI7', 'K3_Ch3_Mod2__AI8', 'Mod2__AI9', 'Mod7_A0', 'Mod7_A1', 'Mod7_A2', 'Mod7_A3'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first[0][\"data\"][\"signals\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aaa84df9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1200,), [-0.09008782699368648, 0.4326112404590785, 6.710733563229876])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = np.array(first[0][\"data\"][\"signals\"][\"K1_Ch1_Mod2__AI0\"])\n",
    "s.shape, [s.min().item(), s.mean().item(), s.max().item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f102100d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8cc14db499042518f766168b8ac6f79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 5000\n",
      "Number of time points per entry: 1200\n",
      "Number of signals: 15\n"
     ]
    }
   ],
   "source": [
    "agg = []\n",
    "\n",
    "# We iterate over all files in the data directory and collect all data\n",
    "for file_path in track(list(data_dir.glob(\"Versuch_*.json\"))):\n",
    "    data = json.loads(file_path.read_text())\n",
    "\n",
    "    for i, data_entry in enumerate(data):\n",
    "        agg.append({\n",
    "            \"meta_data\": {\n",
    "                \"Versuch\": file_path.stem,\n",
    "                \"index\": i,\n",
    "                \"V\": data_entry[\"meta_data\"][\"V\"],\n",
    "                \"T\": data_entry[\"meta_data\"][\"T\"],\n",
    "                \"A\": data_entry[\"meta_data\"][\"A\"],\n",
    "            },\n",
    "            \"data\": {\n",
    "                key: np.array(value)\n",
    "                for key, value in {\n",
    "                    \"time_s\": data_entry[\"data\"][\"time_s\"],\n",
    "                    **data_entry[\"data\"][\"signals\"]\n",
    "                }.items()\n",
    "            }\n",
    "        })\n",
    "\n",
    "# Get signal keys from first entry\n",
    "signal_keys = list(agg[0][\"data\"].keys())\n",
    "n_entries = len(agg)\n",
    "n_points = len(agg[0][\"data\"][\"time_s\"])\n",
    "\n",
    "print(f\"Number of entries: {n_entries}\")\n",
    "print(f\"Number of time points per entry: {n_points}\")\n",
    "print(f\"Number of signals: {len(signal_keys)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9eb127b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data array shape: (5000, 15, 1200)\n"
     ]
    }
   ],
   "source": [
    "# Stack all data into single arrays\n",
    "# Shape: (n_entries, n_signals, n_points)\n",
    "data_array = np.stack([\n",
    "    np.stack([entry[\"data\"][key] for key in signal_keys])\n",
    "    for entry in agg\n",
    "])\n",
    "\n",
    "# Metadata arrays\n",
    "versuch_array = np.array([entry[\"meta_data\"][\"Versuch\"]\n",
    "                         for entry in agg], dtype=\"S64\")\n",
    "index_array = np.array([entry[\"meta_data\"][\"index\"]\n",
    "                       for entry in agg], dtype=np.int32)\n",
    "v_array = np.array([entry[\"meta_data\"][\"V\"] for entry in agg], dtype=np.int32)\n",
    "t_array = np.array([entry[\"meta_data\"][\"T\"] for entry in agg], dtype=np.int32)\n",
    "a_array = np.array([entry[\"meta_data\"][\"A\"] for entry in agg], dtype=np.int32)\n",
    "\n",
    "print(f\"Data array shape: {data_array.shape}\")\n",
    "\n",
    "# Dump that into an HDF5 file for easier access later\n",
    "with h5py.File(data_dir / \"all_data.h5\", \"w\") as h5f:\n",
    "    # Store signal data as single dataset\n",
    "    h5f.create_dataset(\"data\", data=data_array, compression=\"gzip\")\n",
    "\n",
    "    # Store signal names as attribute\n",
    "    h5f[\"data\"].attrs[\"signal_keys\"] = [k.encode() for k in signal_keys]\n",
    "\n",
    "    # Store metadata as datasets\n",
    "    meta_grp = h5f.create_group(\"meta_data\")\n",
    "    meta_grp.create_dataset(\"Versuch\", data=versuch_array)\n",
    "    meta_grp.create_dataset(\"index\", data=index_array)\n",
    "    meta_grp.create_dataset(\"V\", data=v_array)\n",
    "    meta_grp.create_dataset(\"T\", data=t_array)\n",
    "    meta_grp.create_dataset(\"A\", data=a_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "701c040c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HDF5 file size: 490.74 MB\n",
      "HDF5 file verified successfully.\n"
     ]
    }
   ],
   "source": [
    "# Print the file size\n",
    "h5_file_size = (data_dir / \"all_data.hdf5\").stat().st_size / (1024 ** 2)\n",
    "print(f\"HDF5 file size: {h5_file_size:.2f} MB\")\n",
    "\n",
    "# Verify that we can read back the data correctly\n",
    "with h5py.File(data_dir / \"all_data.hdf5\", \"r\") as h5f:\n",
    "    read_data = h5f[\"data\"][:]\n",
    "    read_signal_keys = [k for k in h5f[\"data\"].attrs[\"signal_keys\"]]\n",
    "\n",
    "    assert np.array_equal(data_array, read_data), \"Data mismatch\"\n",
    "    assert read_signal_keys == signal_keys, \"Signal keys mismatch\"\n",
    "    assert np.array_equal(h5f[\"meta_data/Versuch\"][:],\n",
    "                          versuch_array), \"Versuch mismatch\"\n",
    "    assert np.array_equal(h5f[\"meta_data/V\"][:], v_array), \"V mismatch\"\n",
    "    assert np.array_equal(h5f[\"meta_data/T\"][:], t_array), \"T mismatch\"\n",
    "    assert np.array_equal(h5f[\"meta_data/A\"][:], a_array), \"A mismatch\"\n",
    "\n",
    "del agg, data_array  # Free memory\n",
    "\n",
    "print(\"HDF5 file verified successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d8fe78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
